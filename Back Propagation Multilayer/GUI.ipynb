{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58b237f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "from tkinter import messagebox\n",
    "import tkinter.font as tkFont\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from Model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f28d661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genLblTxt(text):\n",
    "    lbl, txt = StringVar(), Entry(Top)\n",
    "    lbl.set(text)\n",
    "    Label(Top, textvariable=lbl).pack(padx=5, pady=5)\n",
    "    txt.pack(padx=5, pady=5)\n",
    "    return txt\n",
    "\n",
    "def getter():\n",
    "    return (\n",
    "        int(txtEnt[0].get()),\n",
    "        [int(nn) for nn in (txtEnt[1].get()).split()],\n",
    "        float(txtEnt[2].get()),\n",
    "        int(txtEnt[3].get()),\n",
    "        int(txtEnt[4].get()),\n",
    "        txtEnt[5].get()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f76e65",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7074842",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X:\\Jupyter\\Penguins-Classifier\\Back Propagation Multilayer\\Model.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1 + np.exp(-val))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.23775773,  1.41861119, -0.4585735 , -0.82874777, -0.30440456,\n",
      "         1.61811971,  2.12739256, -0.75831054],\n",
      "       [-1.17058099, -0.68453305, -0.17410893, -0.14315026, -0.14730625,\n",
      "         1.62037157,  0.272571  , -0.77346396],\n",
      "       [ 1.21280066,  0.8704455 , -0.07098573, -1.72761869,  1.21714468,\n",
      "        -0.5287333 , -1.42173584, -0.98833423],\n",
      "       [ 0.76878804,  1.31146526,  2.2306769 , -0.41607252, -0.33376053,\n",
      "         0.01963669,  0.87720474,  0.85497087],\n",
      "       [ 0.10085809, -0.0296934 , -1.49983507, -0.09590498, -0.28746655,\n",
      "        -1.15412691, -0.69650089, -1.54243223],\n",
      "       [ 0.30968978,  0.01504548,  0.85673324, -0.38649829,  0.42883734,\n",
      "        -0.71177193, -0.18949447, -2.08119346]]), array([[-0.17878126,  1.85730309, -0.24693459,  0.50083784],\n",
      "       [ 0.50515129, -1.8751756 ,  0.36724719,  0.19622601],\n",
      "       [ 0.58320475,  0.66945701,  0.51545583, -0.05609377],\n",
      "       [-0.18140254,  0.93503535,  0.24094891, -1.19032608],\n",
      "       [-0.0491922 ,  0.11537883,  0.27984143,  0.23475874],\n",
      "       [-1.18864324, -0.89636367,  0.89863708, -0.73744233],\n",
      "       [-0.43041623,  2.44311813, -0.10982051,  0.31925713],\n",
      "       [-0.20043973, -0.94287644,  0.49284476,  0.78878815]]), array([[ 0.00392418,  0.29920685,  0.53997217],\n",
      "       [-0.14861657, -0.72341315,  1.21127179],\n",
      "       [-0.89359474, -0.38564141,  0.9834972 ],\n",
      "       [-0.33595407,  0.22182463, -0.14099657]])]\n"
     ]
    }
   ],
   "source": [
    "def modelRUN():\n",
    "    df = pd.read_csv('penguins.csv')\n",
    "    df['gender'] = LabelEncoder().fit_transform(df['gender'])    \n",
    "    df = pd.DataFrame(ColumnTransformer([(df.columns[0], OneHotEncoder(),\n",
    "                        [df.columns.get_loc(df.columns[0])])],\n",
    "                      remainder='passthrough').fit_transform(df),\n",
    "                      columns=['C1', 'C2', 'C3', 'X1', 'X2', 'X3', 'X4', 'X5'])\n",
    "    \n",
    "    try: layers, nn, eta, epochs, bias, activeFn = getter()\n",
    "    except: layers, nn, eta, epochs, bias, activeFn = 2, (8, 4), 0.01, 100, 1, 'Sigmoid'\n",
    "    \n",
    "    df.insert(loc=3, column='bias', value=[bias for _ in range(len(df))])\n",
    "        \n",
    "    C1, C2, C3 = df[:50].sample(frac=1), df[50:100].sample(frac=1), df[100:].sample(frac=1)\n",
    "    trainData = (pd.concat([C1[:30], C2[:30], C3[:30]])).to_numpy()\n",
    "    testData = (pd.concat([C1[30:], C2[30:], C3[30:]])).to_numpy()\n",
    "    \n",
    "    inMat, outMat = np.zeros([len(trainData), 5+1]), np.zeros([len(trainData), 3])\n",
    "    for i in range(len(trainData)):\n",
    "        outMat[i], inMat[i] = trainData[i][0:3], trainData[i][3:]\n",
    "    \n",
    "    weights = list()\n",
    "    weights.append(np.random.randn(5+1, nn[0]))\n",
    "    for i in range(layers-1):\n",
    "        weights.append(np.random.randn(nn[i], nn[i+1]))\n",
    "    weights.append(np.random.randn(nn[-1], 3))\n",
    "    \n",
    "    weights = BackPropagationAlgo(inMat, outMat, weights, activeFn,\n",
    "                                            epochs, eta, layers, nn, bias)\n",
    "    \n",
    "    print(weights)\n",
    "    \n",
    "modelRUN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a70c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictFn():\n",
    "    for i in range(len(txtEnt)):\n",
    "        if txtEnt[i].get() in ('', 'Activation Function >>'):\n",
    "            messagebox.showerror(title=\"error\", message=\"Insert the missing inputs\", parent=Top)\n",
    "            break\n",
    "    else:\n",
    "        #print(getter())\n",
    "        modelRUN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4674b5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3d7581",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Top = Tk()\n",
    "Top.geometry('300x400')\n",
    "Top.title('Back Propagation Algo')\n",
    "Top.resizable(False, False)\n",
    "\n",
    "txtEnt = [0]*6\n",
    "txtEnt[0] = (genLblTxt('No. of Hidden Layers'))\n",
    "txtEnt[1] = (genLblTxt('No. of Neurons\\n(separate by space)'))\n",
    "txtEnt[2] = (genLblTxt('Learning Rate Value'))\n",
    "txtEnt[3] = (genLblTxt('No. of Epochs'))\n",
    "\n",
    "txtEnt[4] = IntVar()\n",
    "cb_obj = Checkbutton(Top, text='Add Bias', variable=txtEnt[4], onvalue=1, offvalue=0)\n",
    "cb_obj.pack()\n",
    "\n",
    "txtEnt[5] = ttk.Combobox(Top, textvariable=StringVar(), state='readonly', values=('Sigmoid', 'TanH'))\n",
    "txtEnt[5].set('Activation Function >>')\n",
    "txtEnt[5].pack(padx=5, pady=5)\n",
    "\n",
    "btn_submit = Button(Top, text='Run', width=10, command=PredictFn, bg='green', fg='yellow')\n",
    "btn_submit.pack(pady=25)\n",
    "\n",
    "Top.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
