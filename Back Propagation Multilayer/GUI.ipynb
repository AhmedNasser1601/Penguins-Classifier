{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58b237f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "from tkinter import messagebox\n",
    "import tkinter.font as tkFont\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from Model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f28d661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genLblTxt(text):\n",
    "    lbl, txt = StringVar(), Entry(Top)\n",
    "    lbl.set(text)\n",
    "    Label(Top, textvariable=lbl).pack(padx=5, pady=5)\n",
    "    txt.pack(padx=5, pady=5)\n",
    "    return txt\n",
    "\n",
    "def getter():\n",
    "    return (\n",
    "        int(txtEnt[0].get()),\n",
    "        [int(nn) for nn in (txtEnt[1].get()).split()],\n",
    "        float(txtEnt[2].get()),\n",
    "        int(txtEnt[3].get()),\n",
    "        int(txtEnt[4].get()),\n",
    "        txtEnt[5].get()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f76e65",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7074842",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X:\\Jupyter\\Penguins-Classifier\\Back Propagation Multilayer\\Model.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1 + np.exp(-val))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.5491651 , -0.74033501,  0.5209306 ,  1.76323186,  0.64024694,\n",
      "         0.65315908, -0.86647539, -1.47768236],\n",
      "       [ 0.61240197, -1.74992962,  0.88682359, -1.95437367, -0.08703626,\n",
      "         0.23174995, -1.62182456,  0.10099592],\n",
      "       [-2.19342017,  1.46196436, -0.24247343, -0.69359271, -0.10304755,\n",
      "        -0.50066228,  0.0545193 , -0.19464979],\n",
      "       [-1.23597654,  1.74303793,  0.11304572,  0.30635344, -0.80359405,\n",
      "         1.12612219,  0.17433639, -1.79116536],\n",
      "       [ 0.29594849,  0.38589983, -0.42081887, -0.04950064, -0.04521699,\n",
      "        -1.40766036, -0.08322304, -0.34441257],\n",
      "       [-0.18852831, -0.48246762, -0.30193956, -0.27002464, -1.90235563,\n",
      "         0.75888506, -0.52308861,  1.10447888]]), array([[-1.32183336, -1.62240205,  1.41281068, -0.06331005],\n",
      "       [-0.99362622,  0.73619501,  1.54557463,  0.35776557],\n",
      "       [ 0.29825703, -1.19539903,  0.3912384 ,  0.22224927],\n",
      "       [ 0.76857068,  1.50994892,  1.79569722, -0.81411895],\n",
      "       [-1.15488241, -1.71228798,  0.09336904,  0.38416788],\n",
      "       [ 0.20935927,  0.10288274, -1.64128682,  1.44125339],\n",
      "       [-2.17617477, -0.33271852,  1.89337679,  1.67728286],\n",
      "       [-0.28978042,  0.6844047 ,  0.75657559, -1.68062034]]), array([[ 0.62921847, -0.86732408, -1.9248798 ],\n",
      "       [-0.60602323,  1.3046879 , -0.97104315],\n",
      "       [-1.21333965,  1.16182535, -0.93176093],\n",
      "       [-1.35620545, -0.63491729,  3.01916331]])]\n"
     ]
    }
   ],
   "source": [
    "def modelRUN():\n",
    "    df = pd.read_csv('penguins.csv')\n",
    "    df['gender'] = LabelEncoder().fit_transform(df['gender'])    \n",
    "    df = pd.DataFrame(ColumnTransformer([(df.columns[0], OneHotEncoder(),\n",
    "                        [df.columns.get_loc(df.columns[0])])],\n",
    "                      remainder='passthrough').fit_transform(df),\n",
    "                      columns=['C1', 'C2', 'C3', 'X1', 'X2', 'X3', 'X4', 'X5'])\n",
    "    \n",
    "    try: layers, nn, eta, epochs, bias, activeFn = getter()\n",
    "    except: layers, nn, eta, epochs, bias, activeFn = 2, (8, 4), 0.01, 100, 1, 'Sigmoid'\n",
    "    \n",
    "    df.insert(loc=3, column='bias', value=[bias for _ in range(len(df))])\n",
    "        \n",
    "    C1, C2, C3 = df[:50].sample(frac=1), df[50:100].sample(frac=1), df[100:].sample(frac=1)\n",
    "    trainData = (pd.concat([C1[:30], C2[:30], C3[:30]])).to_numpy()\n",
    "    testData = (pd.concat([C1[30:], C2[30:], C3[30:]])).to_numpy()\n",
    "    \n",
    "    inMat, outMat = np.zeros([len(trainData), 5+1]), np.zeros([len(trainData), 3])\n",
    "    for i in range(len(trainData)):\n",
    "        outMat[i], inMat[i] = trainData[i][0:3], trainData[i][3:]\n",
    "    \n",
    "    weights = list()\n",
    "    weights.append(np.random.randn(5+1, nn[0]))\n",
    "    for i in range(layers-1):\n",
    "        weights.append(np.random.randn(nn[i], nn[i+1]))\n",
    "    weights.append(np.random.randn(nn[-1], 3))\n",
    "    \n",
    "    weights = BackPropagationAlgo(inMat, outMat, weights, activeFn,\n",
    "                                            epochs, eta, layers, nn, bias)\n",
    "    \n",
    "    print(weights)\n",
    "    \n",
    "modelRUN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a70c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictFn():\n",
    "    for i in range(len(txtEnt)):\n",
    "        if txtEnt[i].get() in ('', 'Activation Function >>'):\n",
    "            messagebox.showerror(title=\"error\", message=\"Insert the missing inputs\", parent=Top)\n",
    "            break\n",
    "    else:\n",
    "        print(getter())\n",
    "        modelRUN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4674b5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b3d7581",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Top = Tk()\n",
    "Top.geometry('300x400')\n",
    "Top.title('Back Propagation Algo')\n",
    "Top.resizable(False, False)\n",
    "\n",
    "txtEnt = [0]*6\n",
    "txtEnt[0] = (genLblTxt('No. of Hidden Layers'))\n",
    "txtEnt[1] = (genLblTxt('No. of Neurons\\n(separate by space)'))\n",
    "txtEnt[2] = (genLblTxt('Learning Rate Value'))\n",
    "txtEnt[3] = (genLblTxt('No. of Epochs'))\n",
    "\n",
    "txtEnt[4] = IntVar()\n",
    "cb_obj = Checkbutton(Top, text='Add Bias', variable=txtEnt[4], onvalue=1, offvalue=0)\n",
    "cb_obj.pack()\n",
    "\n",
    "txtEnt[5] = ttk.Combobox(Top, textvariable=StringVar(), state='readonly', values=('Sigmoid', 'TanH'))\n",
    "txtEnt[5].set('Activation Function >>')\n",
    "txtEnt[5].pack(padx=5, pady=5)\n",
    "\n",
    "btn_submit = Button(Top, text='Run', width=10, command=PredictFn, bg='green', fg='yellow')\n",
    "btn_submit.pack(pady=25)\n",
    "\n",
    "Top.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
