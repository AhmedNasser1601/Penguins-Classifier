{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1fcaa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import preReq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dd32244",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('penguins.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c11d99ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['gender'] = LabelEncoder().fit_transform(df['gender'])\n",
    "scaled_df = pd.DataFrame(preprocessing.MinMaxScaler().fit_transform(df.iloc[:, 1:]), columns=df.iloc[:, 1:].columns)\n",
    "scaled_df['species'] = df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b3b82fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedF = (preReq.INarr[0], preReq.INarr[1])\n",
    "selectedC = (preReq.INarr[2], preReq.INarr[3])\n",
    "weight = np.random.random((2))\n",
    "eta = preReq.INarr[4]\n",
    "epochs = preReq.INarr[5]\n",
    "bias = np.random.randn() if preReq.INarr[6] else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b3adae",
   "metadata": {},
   "source": [
    "---\n",
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c86b1a08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def visualizeData(scaled_df):  # 10 combs\n",
    "    for i in range(len(preReq.Features) - 1):\n",
    "        for j in range(i + 1, len(preReq.Features)):\n",
    "            fL1, fL2 = preReq.Features[i], preReq.Features[j]\n",
    "            f1, f2 = scaled_df[fL1], scaled_df[fL2]\n",
    "\n",
    "            plt.xlabel(fL1)\n",
    "            plt.ylabel(fL2)\n",
    "\n",
    "            CF = [(f1[:50], f2[:50]), (f1[50:100], f2[50:100]), (f1[100:], f2[100:])]\n",
    "            for plot in range(3):\n",
    "                plt.scatter(CF[plot][0], CF[plot][1])\n",
    "\n",
    "            plt.legend([preReq.Classes[0], preReq.Classes[1], preReq.Classes[2]])\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "# visualizeData(scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2366d8f",
   "metadata": {},
   "source": [
    "---\n",
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3425851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "misClass = list()\n",
    "for x in preReq.Classes:\n",
    "    if x not in selectedC:\n",
    "        misClass.append(x)\n",
    "\n",
    "misFeatures = list()\n",
    "for x in preReq.Features:\n",
    "    if x not in selectedF:\n",
    "        misFeatures.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79603966",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaled_df.drop(scaled_df.index[(scaled_df[\"species\"] == misClass[0])], axis=0, inplace=True)\n",
    "scaled_df.drop(columns=misFeatures, axis=1, inplace=True)\n",
    "scaled_df['species'] = scaled_df['species'].replace(selectedC, [1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bdaa475",
   "metadata": {},
   "outputs": [],
   "source": [
    "C1, C2 = (scaled_df[:50]).sample(frac=1), (scaled_df[50:100]).sample(frac=1)\n",
    "C1_train, C1_test, C2_train, C2_test = C1[:30], C1[30:], C2[:30], C2[30:]\n",
    "\n",
    "all_train_data = pd.concat([C1_train, C2_train]).to_numpy()\n",
    "all_test_data = pd.concat([C1_test, C2_test]).to_numpy()\n",
    "\n",
    "train_data, train_target = all_train_data[:, :2], all_train_data[:, 2:]\n",
    "test_data, test_target = all_test_data[:, :2], all_test_data[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8780694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PerceptronAlgo(epochs, weight, bias, eta, train_data, train_target):\n",
    "    import numpy as np\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        predict = (train_data.dot(weight.transpose()) + bias)\n",
    "        yPredTrain = np.where(predict > 0, 1, -1)\n",
    "        for i in range(len(train_target)):\n",
    "            if yPredTrain[i] != train_target[i]:\n",
    "                loss = train_target[i] - yPredTrain[i]\n",
    "                weight += (eta * loss * train_data[i])\n",
    "                bias += (eta * loss) if bias else 0\n",
    "    return yPredTrain\n",
    "\n",
    "yPredTrain = PerceptronAlgo(epochs, weight, bias, eta, train_data, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99c70bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyTrain():\n",
    "    plt.figure(\"Trained Features Figure\")\n",
    "    plt.scatter(x=train_data[:, :1], y=train_data[:, 1:2], c=train_target)\n",
    "    plt.plot(np.array([0, 1]), np.array([(-bias) / weight[1], (-weight[0] - bias) / weight[1]]))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# classifyTrain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba45dd7",
   "metadata": {},
   "source": [
    "---\n",
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "938ad8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest = (test_data.dot(weight.transpose()) + bias)\n",
    "yPredTest = np.where(ytest > 0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f55ebb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConfuionMatrix(target, yPred):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    testCase = list()\n",
    "    confMat = np.zeros([2, 2])\n",
    "\n",
    "    for i in range(len(yPred)):\n",
    "        if target[i] == 1:\n",
    "            if yPred[i] == 1:\n",
    "                confMat[0][0] += 1\n",
    "                testCase.append([int(target[i][0]), yPred[i], '[*]'])\n",
    "            else:\n",
    "                confMat[0][1] += 1\n",
    "                testCase.append([int(target[i][0]), yPred[i], '[ ]'])\n",
    "\n",
    "        elif target[i] == -1:\n",
    "            if yPred[i] == -1:\n",
    "                confMat[1][1] += 1\n",
    "                testCase.append([int(target[i][0]), yPred[i], '[*]'])\n",
    "            else:\n",
    "                confMat[1][0] += 1\n",
    "                testCase.append([int(target[i][0]), yPred[i], '[ ]'])\n",
    "\n",
    "    Cases = pd.DataFrame(testCase, columns=['Real', 'Pred', 'Match'])\n",
    "    return ((np.trace(confMat) / np.sum(confMat)) * 100), confMat, pd.DataFrame(Cases,\n",
    "                                                                                columns=['Real', 'Pred', 'Match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee4afccd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|> Truth Values for Training <|\n",
      "   Training Accuracy:  96.66666666666667 %\n",
      "     Real  Pred Match\n",
      "0      1     1   [*]\n",
      "1      1     1   [*]\n",
      "2      1     1   [*]\n",
      "3      1     1   [*]\n",
      "4      1     1   [*]\n",
      "5      1     1   [*]\n",
      "6      1     1   [*]\n",
      "7      1     1   [*]\n",
      "8      1     1   [*]\n",
      "9      1     1   [*]\n",
      "10     1     1   [*]\n",
      "11     1     1   [*]\n",
      "12     1     1   [*]\n",
      "13     1     1   [*]\n",
      "14     1     1   [*]\n",
      "15     1     1   [*]\n",
      "16     1     1   [*]\n",
      "17     1     1   [*]\n",
      "18     1     1   [*]\n",
      "19     1     1   [*]\n",
      "20     1     1   [*]\n",
      "21     1     1   [*]\n",
      "22     1     1   [*]\n",
      "23     1     1   [*]\n",
      "24     1     1   [*]\n",
      "25     1     1   [*]\n",
      "26     1     1   [*]\n",
      "27     1     1   [*]\n",
      "28     1     1   [*]\n",
      "29     1     1   [*]\n",
      "30    -1    -1   [*]\n",
      "31    -1    -1   [*]\n",
      "32    -1    -1   [*]\n",
      "33    -1    -1   [*]\n",
      "34    -1    -1   [*]\n",
      "35    -1    -1   [*]\n",
      "36    -1    -1   [*]\n",
      "37    -1    -1   [*]\n",
      "38    -1    -1   [*]\n",
      "39    -1    -1   [*]\n",
      "40    -1    -1   [*]\n",
      "41    -1     1   [ ]\n",
      "42    -1    -1   [*]\n",
      "43    -1    -1   [*]\n",
      "44    -1    -1   [*]\n",
      "45    -1    -1   [*]\n",
      "46    -1    -1   [*]\n",
      "47    -1    -1   [*]\n",
      "48    -1    -1   [*]\n",
      "49    -1    -1   [*]\n",
      "50    -1    -1   [*]\n",
      "51    -1    -1   [*]\n",
      "52    -1    -1   [*]\n",
      "53    -1    -1   [*]\n",
      "54    -1    -1   [*]\n",
      "55    -1     1   [ ]\n",
      "56    -1    -1   [*]\n",
      "57    -1    -1   [*]\n",
      "58    -1    -1   [*]\n",
      "59    -1    -1   [*] \n",
      " -----------------------------------\n",
      "|> Truth Values for Testing <|\n",
      "   Testing Accuracy:  65.0 %\n",
      "     Real  Pred Match\n",
      "0      1     1   [*]\n",
      "1      1     1   [*]\n",
      "2      1     1   [*]\n",
      "3      1     1   [*]\n",
      "4      1     1   [*]\n",
      "5      1     1   [*]\n",
      "6      1     1   [*]\n",
      "7      1     1   [*]\n",
      "8      1     1   [*]\n",
      "9      1     1   [*]\n",
      "10     1     1   [*]\n",
      "11     1     1   [*]\n",
      "12     1     1   [*]\n",
      "13     1     1   [*]\n",
      "14     1     1   [*]\n",
      "15     1     1   [*]\n",
      "16     1     1   [*]\n",
      "17     1     1   [*]\n",
      "18     1     1   [*]\n",
      "19     1     1   [*]\n",
      "20    -1     1   [ ]\n",
      "21    -1     1   [ ]\n",
      "22    -1     1   [ ]\n",
      "23    -1     1   [ ]\n",
      "24    -1     1   [ ]\n",
      "25    -1     1   [ ]\n",
      "26    -1    -1   [*]\n",
      "27    -1     1   [ ]\n",
      "28    -1    -1   [*]\n",
      "29    -1     1   [ ]\n",
      "30    -1    -1   [*]\n",
      "31    -1    -1   [*]\n",
      "32    -1     1   [ ]\n",
      "33    -1     1   [ ]\n",
      "34    -1     1   [ ]\n",
      "35    -1    -1   [*]\n",
      "36    -1    -1   [*]\n",
      "37    -1     1   [ ]\n",
      "38    -1     1   [ ]\n",
      "39    -1     1   [ ] \n",
      " -----------------------------------\n"
     ]
    }
   ],
   "source": [
    "preReq.OUTarr[1], confMatTrain, truthValsTrain = ConfuionMatrix(train_target, yPredTrain)\n",
    "print('|> Truth Values for Training <|\\n   Training Accuracy: ', preReq.OUTarr[1], '%\\n', truthValsTrain, '\\n',\n",
    "      '-' * 35)\n",
    "\n",
    "preReq.OUTarr[2], confMatTest, truthValsTest = ConfuionMatrix(test_target, yPredTest)\n",
    "print('|> Truth Values for Testing <|\\n   Testing Accuracy: ', preReq.OUTarr[2], '%\\n', truthValsTest, '\\n', '-' * 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c9ea145",
   "metadata": {},
   "outputs": [],
   "source": [
    "preReq.OUTarr[0] = selectedC[0] if sum(yPredTest) else selectedC[1]\n",
    "preReq.OUTarr[3][0] = confMatTest[0][0]\n",
    "preReq.OUTarr[3][1] = confMatTest[0][1]\n",
    "preReq.OUTarr[3][2] = confMatTest[1][0]\n",
    "preReq.OUTarr[3][3] = confMatTest[1][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
